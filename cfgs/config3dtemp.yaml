scratch_root: "/opt/dlami/nvme/scenario_dreamer_data/" # ${oc.env:SCRATCH_ROOT}  #"/data/lili.gao/datasets/waymo"# scratch root directory, used for datasets and checkpoints
dataset_root: "/opt/dlami/nvme/scenario_dreamer_data"  # root directory for datasets
project_root: /mnt/efs/users/lili.gao/Repos/scenario-dreamer-followup # ${oc.env:PROJECT_ROOT} # project root directory
waymo_data_folder: ${dataset_root}/waymo_open_dataset_motion_v_1_1_0 # path to the Waymo Open Dataset
waymo_train_folder: ${waymo_data_folder}/training # path to the training set of the Waymo Open Dataset
waymo_val_folder: ${waymo_data_folder}/validation # path to the validation set of the Waymo Open Dataset
waymo_test_folder: ${waymo_data_folder}/testing # path to the testing set of the Waymo Open Dataset

# hydra:
#   run:
#     dir: ${project_root}/slurm_logs/${now:%Y.%m.%d}/${now:%H.%M.%S}/${hydra.job.override_dirname}
hydra:
  run:
    dir: ${project_root}/slurm_logs/${now:%Y.%m.%d}/${now:%H.%M.%S}/${ldm.train.run_name}

generate_waymo_dataset:
  output_data_folder_train: ${dataset_root}/scenario_dreamer_waymo/train # output folder for training data
  output_data_folder_val: ${dataset_root}/scenario_dreamer_waymo/val # output folder for validation data
  output_data_folder_test: ${dataset_root}/scenario_dreamer_waymo/test # output folder for test data
  num_workers: 20 # number of workers to use for generating the dataset
  mode: train # or val or test
  chunk_idx: -1 # If chunk_idx >= 0, indexes into the chunk_idx'th chunk of size chunk_size. If chunk_idx=-1, process all chunks in parallel processes
  chunk_size: 50 # size of each chunk to process in parallel processes, if chunk_idx >= 0

preprocess_waymo:
  num_workers: 10 # number of workers to use for preprocessing the dataset
  mode: train # or val or test
  chunk_idx: -1 # If chunk_idx >= 0, indexes into the chunk_idx'th chunk of size chunk_size. If chunk_idx=-1, process all chunks in parallel processes
  chunk_size: 50000 # size of each chunk to process in parallel processes, if chunk_idx >= 0

preprocess_nuplan:
  num_workers: 20 # number of workers to use for preprocessing the dataset
  mode: train # or val or test
  chunk_idx: -1 # If chunk_idx >= 0, indexes into the chunk_idx'th chunk of size chunk_size. If chunk_idx=-1, process all chunks in parallel processes
  chunk_size: 50000 #0 # size of each chunk to process in parallel processes, if chunk_idx >= 0

model_name: autoencoder # or ldm

# hacky way to not have to manually change the dataset name in all config groups from command line
# only dataset_name has to be configured from command line 
# we have to define this as a group because Hydra resolves the defaults-list before it finishes building the root config
# e.g. `python train.py dataset_name=waymo model_name=autoencoder`
defaults:
  - dataset_name: nuplan 
  - dataset@ae.dataset:    ${dataset_name}_autoencoder3dtemp
  - train@ae.train:      ${dataset_name}_autoencoder3d
  - eval@ae.eval:       ${dataset_name}_autoencoder3dtemp
  - model@ae.model:      ${dataset_name}_autoencoder3d
  - datamodule@ae.datamodule: ${dataset_name}_autoencoder3dtemp
  - dataset@ldm.dataset:    ${dataset_name}_ldm3d_image
  - train@ldm.train:      ${dataset_name}_ldm3d_image
  - eval@ldm.eval:       ${dataset_name}_ldm3d_image
  - model@ldm.model:      ${dataset_name}_ldm3d_image
  - datamodule@ldm.datamodule: ${dataset_name}_ldm3d_image
  - model@ldm.gkt: gkt